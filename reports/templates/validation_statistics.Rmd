---
title: "Validation assessment for drone data"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
      number_sections: true
params:
  nim_pkg: output/mcmc/nim_pkg_val.rds
  samples: output/mcmc/fit_val.rds
  nburn: 5e3
  L_train: 1.48
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = FALSE, message = FALSE, 
                      warning = FALSE)
```


# Configuration

```{r load_model, include = FALSE}
library(nimble)

## Load R files and subplans
lapply(list.files("../../R", full.names = TRUE, recursive = TRUE), source)

# load inputs to target model
nim_pkg = readRDS(file.path('..', '..', params$nim_pkg))

# build nimble model, so we can extract priors
droneLengths = nimbleModel(code = model, constants = nim_pkg$consts,
                           data = nim_pkg$data, inits = nim_pkg$inits,
                           name = 'droneLengths')
```

```{r load_samples, include = FALSE}
## for when running w/ 1 chain
samples = readRDS(file.path('..', '..', params$samples))
samples.names = colnames(samples)
burn = 1:params$nburn
```

This report was generated by the target 
<span style="color:blue">`r id_chr()`</span>, which displays
posterior diagnostics for the samples in 
<span style="color:blue">`r basename(params$samples)`</span>.  The file 
contains <span style="color:blue">`r nrow(samples)`</span> posterior samples.


# Posterior summary

```{r L, include = FALSE}
library(coda)
nim_pkg$consts$L_unknown_inds
tgt = grep(pattern = paste('L\\[(', 
                           paste(nim_pkg$consts$L_unknown_inds, collapse = '|'),
                           ')\\]', sep = ''), 
           x = samples.names, value = TRUE)
m = mcmc(samples[-burn, tgt, drop = FALSE])
```

```{r hpd_coverage}
hpds = HPDinterval(m)

# determine which intervals cover the true value
covered = apply(hpds, 1, function(r) {
  all(
    r['lower'] <= params$L_train,
    params$L_train <= r['upper']
  )
})

# empirical coverage rate
print("Empirical HPD coverage rate")
mean(covered)

# contribution of each entry to coverage rate
print("Pct. weight for each interval (i.e., 1/N)")
1/length(covered)
```

```{r validation_rmse}
# RMSE 
print('RMSE')
sqrt(mean((colMeans(m) - params$L_train)^2))
```

```{r validation_mean_bias}
# mean prediction bias
print('Mean prediction bias')
mean(m) - params$L_train
```

```{r validation_score}
library(scoringRules)

# CRPS averaged across validation samples - summarize predictive distribution
# 
# Reference: 
#   Section 4.2
#   Gneiting, T., & Raftery, A. E. (2007). 
#   Strictly proper scoring rules, prediction, and estimation. 
#   Journal of the American statistical Association, 102(477), 359-378.

print("Mean CRPS")
mean(crps_sample(y = rep(params$L_train, ncol(m)), dat = t(m)))
```